# IMDB Sentiment Classification with Transformer

A transformer-based deep learning model for sentiment classification on IMDB movie reviews. This project implements a custom transformer architecture from scratch using PyTorch for binary sentiment classification (positive/negative).

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Training](#training)
- [Evaluation](#evaluation)
- [Inference](#inference)
- [API Deployment](#api-deployment)
- [Frontend Interface](#frontend-interface)
- [Results](#results)
- [License](#license)

## ğŸ¯ Overview

This project implements a transformer-based sentiment classifier that predicts whether a movie review is positive or negative. The model is built from scratch, including:

- Multi-Head Self-Attention mechanism
- Positional Encoding
- Transformer Encoder Blocks
- Custom tokenization and vocabulary building

## ğŸ“ Project Structure

```
RealAi/
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ IMDB Dataset.csv           # Dataset file
â”œâ”€â”€ Starter Notebook.ipynb     # Complete notebook with all steps
â”œâ”€â”€ best_model.pth             # Saved model checkpoint
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py               # Transformer model implementation
â”‚   â”œâ”€â”€ data_preprocessing.py  # Data preprocessing utilities
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â””â”€â”€ predict.py             # Inference script
â”‚
â”œâ”€â”€ api.py                     # FastAPI server for deployment
â”‚
â”œâ”€â”€ templates/                 # Frontend templates
â”‚   â””â”€â”€ index.html             # Web interface
â”‚
â””â”€â”€ saved_models/              # Saved model files (generated after training)
    â”œâ”€â”€ sentiment_model.pth
    â”œâ”€â”€ vocab.json
    â””â”€â”€ model_config.json
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- CUDA (optional, for GPU acceleration)

### Setup

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd RealAi
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“Š Dataset

The project uses the IMDB Movie Reviews dataset containing 50,000 reviews labeled as positive or negative.

- **Download:** [IMDB Dataset](https://drive.google.com/file/d/1aU7Vv7jgodZ0YFOLY7kmSjrPcDDwtRfU/view?usp=sharing)
- **Structure:**
  - `review`: Text of the movie review
  - `sentiment`: Label (positive/negative)

Place the downloaded `IMDB Dataset.csv` file in the project root directory.

## ğŸ—ï¸ Model Architecture

The model uses a custom Transformer encoder architecture:

```
Input Token Indices
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embedding     â”‚  (vocab_size â†’ d_model=256)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Positional    â”‚  (Sinusoidal encoding)
â”‚   Encoding      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Transformer Encoder Block (x4)   â”‚
â”‚   â”œâ”€â”€ Multi-Head Attention (8 heads)â”‚
â”‚   â”œâ”€â”€ Add & LayerNorm               â”‚
â”‚   â”œâ”€â”€ Feed-Forward Network          â”‚
â”‚   â””â”€â”€ Add & LayerNorm               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Global Average â”‚  (Masked pooling)
â”‚    Pooling      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classification â”‚  (d_model â†’ d_model//2 â†’ 2)
â”‚      Head       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Output Logits (Positive/Negative)
```

### Key Components:

- **Multi-Head Self-Attention:** 8 attention heads for capturing different aspects of relationships
- **Positional Encoding:** Sinusoidal encodings for sequence position information
- **Feed-Forward Network:** Position-wise MLP with GELU activation
- **Layer Normalization:** For stable training with residual connections

### Hyperparameters:

| Parameter | Value |
|-----------|-------|
| d_model | 256 |
| num_heads | 8 |
| num_layers | 4 |
| d_ff | 512 |
| max_length | 256 |
| dropout | 0.1 |
| vocab_size | ~25,000 |

## ğŸ“ Training

### Using the Training Script

```bash
python src/train.py --data_path "IMDB Dataset.csv" --epochs 10 --batch_size 32 --learning_rate 1e-4
```

### Training Options

| Argument | Default | Description |
|----------|---------|-------------|
| `--data_path` | `IMDB Dataset.csv` | Path to the dataset |
| `--epochs` | 10 | Number of training epochs |
| `--batch_size` | 32 | Batch size for training |
| `--learning_rate` | 1e-4 | Learning rate |
| `--max_length` | 256 | Maximum sequence length |
| `--d_model` | 256 | Model dimension |
| `--num_heads` | 8 | Number of attention heads |
| `--num_layers` | 4 | Number of transformer layers |
| `--save_path` | `saved_models/` | Path to save model checkpoints |

### Using the Notebook

Alternatively, run all cells in `Starter Notebook.ipynb` for an interactive training experience with visualizations.

## ğŸ“ˆ Evaluation

The model is evaluated using the following metrics:

- **Accuracy:** Overall correct predictions
- **Precision:** True positive rate among positive predictions
- **Recall:** True positive rate among actual positives
- **F1 Score:** Harmonic mean of precision and recall
- **Confusion Matrix:** Visual representation of predictions vs actuals

### Run Evaluation

```bash
python src/train.py --evaluate_only --model_path saved_models/sentiment_model.pth
```

## ğŸ”® Inference

### Using the Prediction Script

```bash
python src/predict.py --text "This movie was absolutely fantastic! Great acting and amazing story."
```

### Interactive Mode

```bash
python src/predict.py --interactive
```

### Python API

```python
from src.predict import SentimentPredictor

# Initialize predictor
predictor = SentimentPredictor("saved_models/sentiment_model.pth")

# Predict sentiment
result = predictor.predict("This movie was fantastic!")
print(f"Sentiment: {result['sentiment']}")
print(f"Confidence: {result['confidence']:.2%}")
```

## ğŸŒ API Deployment

The project includes a FastAPI server for model deployment.

### Start the API Server

```bash
# Start the server
python api.py

# Or using uvicorn directly
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/predict` | POST | Predict sentiment |
| `/health` | GET | Health check |

### API Usage Example

```bash
# Using curl
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "This movie was amazing!"}'
```

```python
# Using Python requests
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"text": "This movie was amazing!"}
)
print(response.json())
```

### Response Format

```json
{
    "text": "This movie was amazing!",
    "sentiment": "positive",
    "confidence": 0.95,
    "positive_probability": 0.95,
    "negative_probability": 0.05
}
```

## ğŸ–¥ï¸ Frontend Interface

Access the web interface at `http://localhost:8000` after starting the API server.

Features:
- Clean, modern UI
- Real-time sentiment prediction
- Confidence visualization
- Responsive design

## ğŸ“Š Results

### Training Results (10 epochs)

| Metric | Value |
|--------|-------|
| Training Accuracy | ~92% |
| Validation Accuracy | ~87% |
| Test F1 Score | ~0.87 |

### Sample Predictions

| Review | Predicted | Confidence |
|--------|-----------|------------|
| "Fantastic movie! Great acting..." | Positive | 95% |
| "Terrible waste of time..." | Negative | 93% |
| "Average film, nothing special..." | Negative | 62% |

## ğŸ› ï¸ Technical Details

### Text Preprocessing

1. Convert to lowercase
2. Remove HTML tags
3. Remove URLs
4. Remove special characters (keep only letters and spaces)
5. Remove extra whitespace
6. Tokenize and convert to indices
7. Pad/truncate to fixed length (256 tokens)

### Training Configuration

- **Optimizer:** AdamW with weight decay (0.01)
- **Scheduler:** Cosine Annealing LR
- **Loss Function:** CrossEntropyLoss
- **Gradient Clipping:** max_norm=1.0
- **Early Stopping:** Based on validation accuracy

## ğŸ“„ License

This project is created for the RealAI Text Classification Challenge.

## ğŸ™ Acknowledgments

- IMDB dataset for movie reviews
- PyTorch team for the deep learning framework
- "Attention is All You Need" paper for transformer architecture

---

**Note:** Make sure to place the `IMDB Dataset.csv` file in the project root before training.
